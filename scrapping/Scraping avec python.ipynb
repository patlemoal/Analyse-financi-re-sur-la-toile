{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping avec python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ionos.fr/digitalguide/sites-internet/developpement-web/web-scraping-avec-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sellenium\n",
    "\n",
    "Beautiful soupe\n",
    "\n",
    "Autoscraper\n",
    "\n",
    "Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy est un framework open-source permettant la création de robots d'indexation. Développé en Python, il dispose d'une forte communauté, offrant de nombreux modules supplémentaires. La première version stable a été publiée en septembre 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy est un outil créer spécifique pour effectuer des requêtes, scraper et sauvegarder des données sur le web il se suffit à lui même pour construire un projet de webscraping robuste \n",
    "tandis que BeautifulSoup est un package utilitaire qui nous sera seulement utile pour accéder aux éléments d’une page web, il sera souvent nécessaire d’importer des librairies supplémentaires tels que requests ou urllib2 et d’autres pour avoir l’étendu des fonctionnalités de Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’outil de web scraping Python Scrapy utilise un analyseur syntaxique HTML pour extraire les informations du code source HTML de la page. Par conséquent, un web scraping avec Scrapy suit le schéma suivant :\n",
    "\n",
    "URL → requête HTTP → HTML → Scrapy\n",
    "\n",
    "Le développement d’un scraper avec Scrapy repose sur un concept clé : les « web spiders », de petits programmes basés sur Scrapy. Chaque spider est programmé pour le scraping d’un site Internet précis et se balance d’une page à l’autre, d’où son nom de « spider » (fr. « araignée »). La programmation orientée objet est utilisée dans ce cadre : chaque spider est une classe Python propre.\n",
    "\n",
    "En dehors du paquet Python à proprement parler, l’installation de Scrapy s’accompagne d’un outil de ligne de commande. Cette « scrapy shell » permet de commander les spiders. D’autre part, les spiders existants peuvent être chargés sur le cloud Scrapy où les spiders seront exécutés selon un programme. De cette façon, vous pouvez scraper les sites les plus volumineux sans que votre ordinateur ou votre connexion Internet personnels aient à en faire les frais. Il est également possible de mettre en place votre propre serveur de web scraping avec le logiciel open source Scrapyd.\n",
    "\n",
    "Scrapy est une plate-forme sophistiquée pour le web scraping avec Python. L’architecture de cet outil est axée sur les besoins des projets professionnels. Scrapy contient ainsi un canal intégré pour traiter les données scrapées. Dans Scrapy, la consultation de la page est effectuée de manière asynchrone, ce qui signifie que plusieurs pages peuvent être téléchargées en parallèle. Scrapy convient ainsi parfaitement aux projets de scraping avec un grand volume de pages à traiter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principe de fonctionnement\n",
    "\n",
    "    définition des urls initiales\n",
    "    parsing des pages\n",
    "    extraction des données\n",
    "    extraction des urls à suivre\n",
    "    traitement des données\n",
    "    itération suivante...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy sera disponible dans votre environnement virtuel, mais pas en dehors. Vos scripts ne marcheront pas tant qu’il ne sera pas activé !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour lancer les scripts de scrapping il faut se déplacer dans le dossier NOM_DE_VOTRE_PROJET_SCRAPY qui vient d’être créé. On notera que des fichiers sont déjà présents dans ce dossiers. Ils sont nécessaires pour que Scrapy puisse faire tourner vos crawlers.\n",
    "\n",
    "Vos scripts de crawling iront ensuite se placer dans NOM_DE_VOTRE_PROJET_SCRAPY/spiders/.\n",
    "\n",
    "Créons un script, par exemple crawling_data.py. Je fournis ici un exemple de code. Notez que le crawling ici se fera via une API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pip install scrapy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m venv /path/vers/projet/env_nom_de_votre_projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url = 'https://myanimelist.net/manga.php?letter=B'\n",
    "fetch(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapy shell \"http://quotes.toscrape.com/page/1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [3]: for quote in response.css(\"div.quote\"):\n",
    "  text = quote.css(\"span.text::text\").get()\n",
    "  author = quote.css(\"small.author::text\").get()\n",
    "  tags = quote.css(\"div.tags a.tag::text\").getall()\n",
    "  print(dict(text=text, author=author, tags=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}\n",
    "{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}\n",
    "{'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']}\n",
    "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen', 'tags': ['aliteracy', 'books', 'classic', 'humor']}\n",
    "{'text': \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", 'author': 'Marilyn Monroe', 'tags': ['be-yourself', 'inspirational']}\n",
    "{'text': '“Try not to become a man of success. Rather become a man of value.”', 'author': 'Albert Einstein', 'tags': ['adulthood', 'success', 'value']}\n",
    "{'text': '“It is better to be hated for what you are than to be loved for what you are not.”', 'author': 'André Gide', 'tags': ['life', 'love']}\n",
    "{'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\", 'author': 'Thomas A. Edison', 'tags': ['edison', 'failure', 'inspirational', 'paraphrased']}\n",
    "{'text': \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", 'author': 'Eleanor Roosevelt', 'tags': ['misattributed-eleanor-roosevelt']}\n",
    "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin', 'tags': ['humor', 'obvious', 'simile']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"2000\"\n",
       "            height=\"2000\"\n",
       "            src=\"a.png\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1b66d7bc580>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame, display\n",
    "filepath = \"a.png\"\n",
    "IFrame(filepath, width=2000, height=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " CONCLUSION\n",
    " agréger des données\n",
    "extraire et structurer des données web\n",
    "synchroniser des données"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
